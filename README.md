# Periodical Moving Average Accelerates Gradient Accumulation for Post-Training
This is an official implimentation of **AdamW-PMA** and **Lion-PMA** in the paper "Periodical Moving Average Accelerates Gradient Accumulation for Post-Training".
The code is based on [Adam-mini](https://github.com/zyushun/Adam-mini).


## Examples to use
Install the dependencies as [Adam-mini](https://github.com/zyushun/Adam-mini).
```
pip install adam-mini
```

Then run the sample script.
```
bash sft.py
```
or 
```
bash dep.py
```